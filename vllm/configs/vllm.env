MODEL_NAME=gemma3-12b-it
MODEL_BASE_DIR=/home/h202403659/LLM-Server/models/llm
HOST=0.0.0.0
PORT=8000
TENSOR_PARALLEL_SIZE=2
GPU_MEMORY_UTILIZATION=0.70 
MAX_MODEL_LEN=4096
DTYPE=auto
TRUST_REMOTE_CODE=false
ENABLE_CHUNKED_PREFILL=true
MAX_NUM_BATCHED_TOKENS=1024
SWAP_SPACE=4
KV_CACHE_DTYPE=auto
NCCL_P2P_DISABLE=1
NCCL_SHM_DISABLE=1
NCCL_CUMEM_ENABLE=0
NCCL_SOCKET_IFNAME=lo
CUDA_VISIBLE_DEVICES=0,1
TORCHINDUCTOR_DISABLE=1
TORCHDYNAMO_DISABLE=1
EXTRA_ARGS="--enforce-eager --disable-custom-all-reduce"